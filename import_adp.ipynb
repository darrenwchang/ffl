{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenchang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Cafari/537.36\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.Logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(l):\n",
    "    passed = 0\n",
    "    while passed == 0:\n",
    "        try:\n",
    "            page = requests.get(l, headers=headers)\n",
    "            # print(page)\n",
    "            if page.status_code == 429:\n",
    "                logger.info(\"retrying after \", int(page.headers[\"Retry-After\"]))\n",
    "                time.sleep(int(page.headers[\"Retry-After\"]))\n",
    "            else:\n",
    "                passed = 1\n",
    "        except:\n",
    "            passed = 0\n",
    "            logger.info(\"trying to download \", l)\n",
    "            time.sleep(5)\n",
    "\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adp(year_start: int, year_end: int, bl) -> pd.DataFrame:\n",
    "    years = np.arange(year_start, year_end + 1)\n",
    "\n",
    "    dfs = []\n",
    "    for y in tqdm(years):\n",
    "        logger.info(f\"scraping {y}\")\n",
    "        page = get_page(f\"{bl}{y}\")\n",
    "\n",
    "        logger.info(f\"parsing for {y}...\")\n",
    "\n",
    "        df = pd.read_html(page.content)[0]\n",
    "\n",
    "        # return df\n",
    "\n",
    "        # add a few metadata columns\n",
    "        # df[\"bye\"] = df[\"Player Team (Bye)\"].apply(\n",
    "        #     lambda x: re.findall(r\"\\d+\", x)[0] if re.findall(r\"\\d+\", x) else None\n",
    "        # )\n",
    "        df[\"Season\"] = [y] * len(df)\n",
    "\n",
    "        df.columns = df.columns.str.replace(\" \", \"\").str.lower()\n",
    "\n",
    "        code = BeautifulSoup(page.content)\n",
    "        trs = code.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "        ids = []\n",
    "        for tr in trs:\n",
    "            # print(tr)\n",
    "            nid = int(tr.find_all(\"a\")[0][\"class\"][-1].split(\"-\")[-1])\n",
    "            # print(nid)\n",
    "            ids.append(nid)\n",
    "\n",
    "        df[\"pid\"] = ids\n",
    "        df.assign(scrape_datetime=pd.Timestamp.now())\n",
    "        dfs.append(df)\n",
    "        dfs\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projs(year_start: int, year_end: int, bl) -> pd.DataFrame:\n",
    "    years = np.arange(year_start, year_end + 1)\n",
    "\n",
    "    dfs = []\n",
    "    for y in tqdm(years):\n",
    "        logger.info(f\"scraping {y}\")\n",
    "        page = get_page(f\"{bl}{y}\")\n",
    "\n",
    "        logger.info(f\"parsing for {y}...\")\n",
    "\n",
    "        df = pd.read_html(page.content)[0]\n",
    "\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [\"_\".join(col).lower() for col in df.columns]\n",
    "            df = df.rename({\"unnamed: 0_level_0_player\": \"player\"}, axis=1)\n",
    "\n",
    "        else:\n",
    "            df.columns = df.columns.str.lower()\n",
    "\n",
    "        # return df\n",
    "\n",
    "        # add a few metadata columns\n",
    "        # df[\"bye\"] = df[\"Player Team (Bye)\"].apply(\n",
    "        #     lambda x: re.findall(r\"\\d+\", x)[0] if re.findall(r\"\\d+\", x) else None\n",
    "        # )\n",
    "        df[\"Season\"] = [y] * len(df)\n",
    "\n",
    "        code = BeautifulSoup(page.content)\n",
    "        trs = code.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "        ids = []\n",
    "        for tr in trs:\n",
    "            # print(tr)\n",
    "            nid = int(tr.find_all(\"a\")[0][\"class\"][-1].split(\"-\")[-1])\n",
    "            # print(nid)\n",
    "            ids.append(nid)\n",
    "\n",
    "        df[\"pid\"] = ids\n",
    "        df.assign(scrape_datetime=pd.Timestamp.now())\n",
    "        dfs.append(df)\n",
    "        dfs\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "adps = get_adp(2019, 2024, \"https://www.fantasypros.com/nfl/adp/ppr-overall.php?year=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "adps = pd.concat(adps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "adps.to_csv(\"data/adp_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "for pos in [\"qb\", \"rb\", \"wr\", \"te\"]:  # , \"k\", \"dst\"]:\n",
    "    dat = pd.concat(\n",
    "        get_projs(\n",
    "            2019,\n",
    "            2024,\n",
    "            f\"https://www.fantasypros.com/nfl/stats/{pos}.php?scoring=PPR&roster=e&range=full&year=\",\n",
    "        )\n",
    "    )\n",
    "    dat['pos'] = pos\n",
    "\n",
    "\n",
    "    stats = pd.concat([stats, dat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_stats = stats.copy()\n",
    "off_stats = off_stats.rename({\"unnamed: 1_level_0_player\": \"player\"}, axis=1)\n",
    "off_stats = off_stats.drop(\"unnamed: 0_level_0_rank\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_stats.to_csv(\"data/offensive_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "for pos in [\"k\", \"dst\"]:\n",
    "    dat = pd.concat(\n",
    "        get_projs(\n",
    "            2019,\n",
    "            2024,\n",
    "            f\"https://www.fantasypros.com/nfl/stats/{pos}.php?scoring=PPR&roster=e&range=full&year=\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    stats = pd.concat([stats, dat])\n",
    "    stats['pos'] = pos\n",
    "\n",
    "    stats.to_csv(f\"data/{pos}_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "for pos in [\"qb\", \"rb\", \"wr\", \"te\", \"flex\"]:\n",
    "    dat = pd.concat(\n",
    "        get_projs(\n",
    "            2019,\n",
    "            2024,\n",
    "            f\"https://www.fantasypros.com/nfl/projections/{pos}.php?week=draft&scoring=PPR&week=draft&year=\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dat['pos'] = pos\n",
    "\n",
    "\n",
    "    stats = pd.concat([stats, dat])\n",
    "\n",
    "    # stats.to_csv(f\"data/{pos}_projections.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_stats = stats.copy()\n",
    "# off_stats = off_stats.rename({\"unnamed: 1_level_0_player\": \"player\"}, axis=1)\n",
    "# off_stats = off_stats.drop(\"unnamed: 0_level_0_rank\", axis=1)\n",
    "off_stats.to_csv(\"data/offensive_projections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "for pos in [\"dst\"]:\n",
    "    dat = pd.concat(\n",
    "        get_projs(\n",
    "            2024,\n",
    "            2024,\n",
    "            f\"https://www.fantasypros.com/nfl/projections/{pos}.php?week=draft&scoring=PPR&week=draft&year=\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dat['pos'] = pos\n",
    "\n",
    "    stats = pd.concat([stats, dat])\n",
    "\n",
    "    # stats.to_csv(f\"data/{pos}_projections.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv('data/dst_projections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "for pos in [\"k\"]:\n",
    "    dat = pd.concat(\n",
    "        get_projs(\n",
    "            2024,\n",
    "            2024,\n",
    "            f\"https://www.fantasypros.com/nfl/projections/{pos}.php?week=draft&scoring=PPR&week=draft&year=\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dat['pos'] = pos\n",
    "\n",
    "    stats = pd.concat([stats, dat])\n",
    "\n",
    "    # stats.to_csv(f\"data/{pos}_projections.csv\")\n",
    "\n",
    "    stats.to_csv('data/k_projections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
